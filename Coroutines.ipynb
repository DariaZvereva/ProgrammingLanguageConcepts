{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "vQjltCZ4brpA"
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "adWND5UjbPUB"
   },
   "source": [
    "# Корутины"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z6gmGzGIa0cL"
   },
   "source": [
    "С помощью `yield` можно легко писать бесконечные генераторы.\n",
    "\n",
    "Например, бесконечный поток чисел Фибоначчи:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "e2Lg74Y9UH-L"
   },
   "outputs": [],
   "source": [
    "def fibonacci_generator():\n",
    "    a, b = 1, 1\n",
    "    while True:\n",
    "        yield a;\n",
    "        a, b = b, a + b\n",
    "        \n",
    "gen = fibonacci_generator()\n",
    "# print(next(gen))\n",
    "# print(next(gen))\n",
    "# print(next(gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6fmxR_jgXuYY"
   },
   "source": [
    "А если хочется получить сразу несколько первых элементов из генератора?\n",
    "\n",
    "**Задание** Напишите функцию-генератор, которая будет выдавать элементы до тех пор, пока не наберется нужное количество (`n`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 421,
     "status": "ok",
     "timestamp": 1522328082624,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "YuEU7h3YW_E4",
    "outputId": "6228fccf-70d9-4c51-f16d-c1675f2ea090"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 3, 5]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def take(generator, n):\n",
    "    for i in range(n):\n",
    "      yield next(generator)\n",
    "        \n",
    "list(take(fibonacci_generator(), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y1s7TVDJaddz"
   },
   "source": [
    "**Задание** Напишите функцию, которая будет выдавать только четные числа Фибоначчи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 622,
     "status": "ok",
     "timestamp": 1522328448208,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "5E0D1xdNVsxf",
    "outputId": "807e2441-0fa9-4714-c349-4b4cd62f1da0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 8, 34, 144, 610]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def even_num_generator(num_generator):\n",
    "    for a in num_generator:\n",
    "      if a % 2 == 0:\n",
    "        yield a\n",
    "\n",
    "list(take(even_num_generator(fibonacci_generator()), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hYp0GCywapAx"
   },
   "source": [
    "Другая доступная операция - `send`:  \n",
    "![send](https://image.ibb.co/dbKyLS/2018_03_29_13_58_49.png=x300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 52,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 547,
     "status": "ok",
     "timestamp": 1522328627772,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "GToi7jRKaNuL",
    "outputId": "afd412b8-78c4-4b55-fdca-b01ac43113d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got Hello\n",
      "Got World\n"
     ]
    }
   ],
   "source": [
    "def receiver():\n",
    "    while True:\n",
    "        item = yield\n",
    "        print('Got', item)\n",
    "\n",
    "recv = receiver()\n",
    "next(recv)\n",
    "recv.send('Hello')\n",
    "recv.send('World')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ppitp0YmbgqI"
   },
   "source": [
    "## N-граммная языковая модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 190,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 5549,
     "status": "ok",
     "timestamp": 1522328652869,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "15fhnu6GtlGv",
    "outputId": "7a0cfefa-0ffb-4183-f0f5-00d64610c597"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "старик вытягивает сети\r",
      "\r\n",
      "они пусты и лишь в конце\r",
      "\r\n",
      "записка рыба недоступна\r",
      "\r\n",
      "или вне действия сети\r",
      "\r\n",
      "\r",
      "\r\n",
      "олег адепт шизофрении\r",
      "\r\n",
      "шагает бодро из окна\r",
      "\r\n",
      "и жызнь летит перед глазами\r",
      "\r\n",
      "да не одна а сразу две\r",
      "\r\n",
      "\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget -qq -O perashki.txt https://share.abbyy.com/index.php/s/Y86O2aRLOcdnNWv/download\n",
    "  \n",
    "!head perashki.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BC1cbnJRbwFx"
   },
   "source": [
    "Давайте посчитаем частотности слов в файле:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 54,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 1224,
     "status": "ok",
     "timestamp": 1522328693081,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "1jJUv-BZbuRW",
    "outputId": "84726796-b7f4-41a8-ea8f-f07630205e5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('и', 24199), ('в', 17829), ('не', 10508), ('на', 10145), ('я', 9481), ('а', 8950), ('с', 5802), ('что', 4487), ('как', 4430), ('он', 3343), ('но', 3295), ('у', 2899), ('ты', 2797), ('мне', 2794), ('олег', 2752), ('по', 2707), ('за', 2659), ('из', 2481), ('к', 2382), ('то', 2317), ('вот', 2143), ('когда', 2125), ('все', 1920), ('так', 1639), ('меня', 1627), ('мы', 1600), ('от', 1492), ('его', 1427), ('это', 1343), ('нет', 1302), ('там', 1296), ('всё', 1216), ('под', 1204), ('сказал', 1187), ('же', 1105), ('для', 1063), ('чтоб', 1056), ('был', 1043), ('потом', 1016), ('о', 1011), ('их', 986), ('кто', 980), ('где', 955), ('есть', 952), ('вдруг', 943), ('она', 916), ('теперь', 910), ('оксана', 901), ('вы', 888), ('про', 847), ('ну', 842), ('до', 838), ('без', 825), ('уже', 817), ('только', 807), ('мой', 764), ('бы', 748), ('нас', 676), ('сегодня', 652), ('тебя', 639), ('ни', 633), ('они', 610), ('день', 609), ('да', 593), ('во', 586), ('тут', 584), ('нам', 581), ('если', 575), ('два', 569), ('вас', 566), ('раз', 562), ('смерть', 554), ('всех', 550), ('со', 544), ('себе', 538), ('себя', 537), ('один', 533), ('вам', 529), ('лишь', 515), ('олега', 513), ('или', 510), ('евгений', 506), ('тебе', 501), ('тот', 500), ('ведь', 500), ('ему', 499), ('здесь', 499), ('люди', 494), ('просто', 486), ('три', 480), ('исус', 480), ('глаза', 472), ('чтобы', 471), ('пока', 471), ('вчера', 468), ('может', 462), ('её', 460), ('говорит', 451), ('будет', 447), ('опять', 438)]\n"
     ]
    }
   ],
   "source": [
    "word_counts = Counter()\n",
    "with open('perashki.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        for word in line.strip().split():\n",
    "            if len(word) != 0:\n",
    "                word_counts[word] += 1\n",
    "                \n",
    "print(word_counts.most_common(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NB1HcZyNcTN1"
   },
   "source": [
    "Почему бы не разнести чтение файла и получение отдельных токенов и их обработку?\n",
    "\n",
    "Тогда при чтении легко можно будет добавлять некоторую предобработку - например, токенизацию не по пробелам, а с помощью nltk, не изменяя работу обработчика.\n",
    "\n",
    "**Задание** Напишите `parser` - функцию, которая будет выдавать поток токенов из файла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 52,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 710,
     "status": "ok",
     "timestamp": 1522329037951,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "5IM9HOBEchqy",
    "outputId": "97fadfb0-3acd-4e9e-8cf8-627c51bf8d4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "старик\n",
      "вытягивает\n"
     ]
    }
   ],
   "source": [
    "def parser(path):\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "      for line in f:\n",
    "          for word in line.strip().split():\n",
    "              yield word\n",
    "\n",
    "pars = parser(\"perashki.txt\")\n",
    "\n",
    "print(next(pars))\n",
    "print(next(pars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sHKOg_mPdErP"
   },
   "source": [
    "Раз у нас есть такая удобная функция, почему бы не использовать её для чего-то интересного.\n",
    "\n",
    "Напишем N-граммную языковую модель.\n",
    "\n",
    "Языковая модель - это штука, которая умеет оценивать вероятности $\\mathbf{P}(w_1, \\ldots, w_n) = \\prod_k \\mathbf{P}(w_k|w_{k-1}, \\ldots, w_{1})$.\n",
    "\n",
    "N-граммная языковая модель приближает эту вероятность, используя предположение, что вероятность токена зависит только от недавней истории: $\\mathbf{P}(w_k|w_1, \\ldots, w_{k-1}) = \\mathbf{P}(w_k|w_{k-1}, \\ldots, w_{k-N + 1})$.\n",
    "\n",
    "Для начала нужно собрать статистику. Для простоты будем работать с триграммной моделью, а значит - нужно собрать информацию:\n",
    "- о триграммных частотностях $(w_{i-2}, w_{i-1}) \\to C(w_i)$ - то есть о числе раз, когда слово $w_i$ шло за парой $w_{i-2}, w_{i-1}$\n",
    "- о биграммных частотностях $(w_{i-1}) \\to C(w_i)$\n",
    "- об униграммных частотностях $() \\to C(w_i)$\n",
    "\n",
    "**Задание** Напишите функцию, которая будет из потока токенов формировать и выдавать наружу пары (ngram, next_word)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "uFd5wu12de8o"
   },
   "outputs": [],
   "source": [
    "def compose_ngram(tokens_stream):\n",
    "  #    <yields trigrams, bigrams and unigrams composed from tokens stream>\n",
    "  first = next(tokens_stream)\n",
    "  second = next(tokens_stream)\n",
    "  for third in tokens_stream:\n",
    "    yield ((), first)\n",
    "    yield ((first, ), second)\n",
    "    yield ((first, second), third)\n",
    "    first = second\n",
    "    second = third\n",
    " \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 582,
     "status": "ok",
     "timestamp": 1522330440076,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "L4F3I4fL68ma",
    "outputId": "0043dd1b-2871-4cb2-9f05-94ae0bde8b82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((), 'и')\n",
      "(('и',), 'заперла')\n",
      "(('и', 'заперла'), 'окно')\n",
      "((), 'заперла')\n",
      "(('заперла',), 'окно')\n",
      "(('заперла', 'окно'), 'не')\n",
      "((), 'окно')\n",
      "(('окно',), 'не')\n",
      "(('окно', 'не'), 'дав')\n"
     ]
    }
   ],
   "source": [
    "ngrams = compose_ngram(pars)\n",
    "print(next(ngrams))\n",
    "print(next(ngrams))\n",
    "print(next(ngrams))\n",
    "print(next(ngrams))\n",
    "print(next(ngrams))\n",
    "print(next(ngrams))\n",
    "print(next(ngrams))\n",
    "print(next(ngrams))\n",
    "print(next(ngrams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pF3D8X4jis0r"
   },
   "source": [
    "Соберем статистику:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "q50XPTgReYC_"
   },
   "outputs": [],
   "source": [
    "def collect_stat(path):\n",
    "    ngrams_counter = defaultdict(Counter)\n",
    "    for ngram in compose_ngram(parser(path)):\n",
    "        ngrams_counter[ngram[0]][ngram[1]] += 1\n",
    "    \n",
    "    return ngrams_counter\n",
    "\n",
    "ngrams_counter = collect_stat('perashki.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YdFzXmxLjJrk"
   },
   "source": [
    "Теперь генерировать будем так: пусть есть некоторый уже сгенерированный набор слов (возможно, пустой).\n",
    "\n",
    "Тогда проверяем, есть ли статистика для последних двух слов - если есть, генерируем с помощью неё новое. Нет - тогда смотрим статистику для только одного слова. И так далее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "cCy_cUEdnYLH"
   },
   "outputs": [],
   "source": [
    "def sample_token(ngrams_counter, ngram):\n",
    "    probs = np.array(list(ngrams_counter[ngram].values()))\n",
    "    probs = probs / np.sum(probs)\n",
    "    return np.random.choice(list(ngrams_counter[ngram]), p=probs)  \n",
    "  \n",
    "def generate_token(ngrams_counter):\n",
    "    #<generates next token using >\n",
    "    first = sample_token(ngrams_counter, ())\n",
    "    if (first, ) in ngrams_counter:\n",
    "      second = sample_token(ngrams_counter, (first,))\n",
    "    else:\n",
    "      second = sample_token(ngrams_counter, ())\n",
    "    while True:\n",
    "      if (first, second) in ngrams_counter:\n",
    "        third = sample_token(ngrams_counter, (first, second))\n",
    "      elif second in ngrams_counter:\n",
    "        third = sample_token(ngrams_counter, second)\n",
    "      else:\n",
    "        third = sample_token(ngrams_counter, ())\n",
    "      yield third\n",
    "      first = second\n",
    "      second = third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 537,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 583,
     "status": "ok",
     "timestamp": 1522332173420,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "cVtPIg6wkqyH",
    "outputId": "00a2a5dd-f0ab-4c8a-dc35-1649c0b02b0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['вы',\n",
       " 'на',\n",
       " 'ты',\n",
       " 'на',\n",
       " 'глянцевых',\n",
       " 'журналах',\n",
       " 'то',\n",
       " 'на',\n",
       " 'коралл',\n",
       " 'то',\n",
       " 'на',\n",
       " 'мальков',\n",
       " 'сегодня',\n",
       " 'умерла',\n",
       " 'собака',\n",
       " 'а',\n",
       " 'ты',\n",
       " 'внимательно',\n",
       " 'прильнул',\n",
       " 'ко',\n",
       " 'рту',\n",
       " 'великого',\n",
       " 'вождя',\n",
       " 'давайте',\n",
       " 'в',\n",
       " 'городе',\n",
       " 'осталось',\n",
       " 'не',\n",
       " 'двадцать',\n",
       " 'шесть']"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(take(generate_token(ngrams_counter), 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "bOC0BtbuBy9u"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Copy of Coroutines.ipynb",
   "provenance": [
    {
     "file_id": "1lz9vO6Ue5zOiowEx0-koXNiejBrrnbj0",
     "timestamp": 1522332385794
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
